{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlairStack.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "uTVE0pZWig4O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing data"
      ]
    },
    {
      "metadata": {
        "id": "NyK3W12Cw1oN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1GhyH4k9C4uPRnMAMKhJYOqa-V9Tqt4q8'\n",
        "train1 = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1q0jIkWkePF509qtHzynMBjrDUIgNV2uk'\n",
        "test1 = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0oTnoYuimAi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "metadata": {
        "id": "nrLZ3N9Xw5Kt",
        "colab_type": "code",
        "outputId": "7c31c7d7-c5ba-4813-dc99-5d6286bfeeb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1584
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install torch\n",
        "!pip install flair\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import flair\n",
        "import nltk\n",
        "import re\n",
        "import torch\n",
        "from flair.data import TaggedCorpus\n",
        "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 32kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6256e000 @  0x7fd0a50d32a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n",
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/6a/fea4f9533feea65f8b2ff3d6a9934dba6227df81bbc180915cbd30c5db95/flair-0.4.0.tar.gz (70kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.0)\n",
            "Collecting gensim==3.4.0 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 22.6MB 2.2MB/s \n",
            "\u001b[?25hCollecting typing==3.6.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/05/2b/2b05bf1d5a9dd450447c9a5df3e118a465e5d3cb12b73b7220a5064a403f/typing-3.6.4-py3-none-any.whl\n",
            "Collecting tqdm==4.26.0 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/43/19c9fee28110cd47f73e6bc596394337fe9f3e5825b4de402bbf30b3beb5/tqdm-4.26.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 26.5MB/s \n",
            "\u001b[?25hCollecting segtok==1.5.7 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Collecting matplotlib==3.0.0 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/89/dd823436a5f8d5ca9304b51b554863bfd366ca84708d5812f5ee87c923bc/matplotlib-3.0.0-cp36-cp36m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.8MB 4.0MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K    100% |████████████████████████████████| 798kB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Collecting sqlitedict==1.6.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting deprecated==1.2.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/cb/c1a39ee51e3042df8b284e22c9c440ffad1c25f451bddd4bf9a8dc17cd75/Deprecated-1.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: hyperopt==0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.1)\n",
            "Collecting pytorch-pretrained-bert==0.3.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/85/de4dd7e018a197280752881adf7b4142886f20155145f641f7c803c0018a/pytorch_pretrained_bert-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.4.0->flair) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.4.0->flair) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.4.0->flair) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from segtok==1.5.7->flair) (2018.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0->flair) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0->flair) (2.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0->flair) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.20.2)\n",
            "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated==1.2.4->flair) (1.11.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.1->flair) (3.7.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.1->flair) (2.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.3.0->flair) (1.9.78)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.3.0->flair) (2.18.4)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.4.0->flair) (0.98)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.0->flair) (40.6.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt==0.1.1->flair) (4.3.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.3.0->flair) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.78 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.3.0->flair) (1.12.78)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.3.0->flair) (0.1.13)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.3.0->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.3.0->flair) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.3.0->flair) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.3.0->flair) (1.22)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.78->boto3->pytorch-pretrained-bert==0.3.0->flair) (0.14)\n",
            "Building wheels for collected packages: flair, segtok, mpld3, sqlitedict\n",
            "  Running setup.py bdist_wheel for flair ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/54/1c/24/39ec59521bb1a83306cf5224a50f99aad60b55dd3b42d32ed0\n",
            "  Running setup.py bdist_wheel for segtok ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Running setup.py bdist_wheel for mpld3 ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Running setup.py bdist_wheel for sqlitedict ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "Successfully built flair segtok mpld3 sqlitedict\n",
            "\u001b[31myellowbrick 0.9 has requirement matplotlib<3.0,>=1.5.1, but you'll have matplotlib 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gensim, typing, tqdm, segtok, matplotlib, mpld3, sqlitedict, deprecated, pytorch-pretrained-bert, flair\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: matplotlib 3.0.2\n",
            "    Uninstalling matplotlib-3.0.2:\n",
            "      Successfully uninstalled matplotlib-3.0.2\n",
            "Successfully installed deprecated-1.2.4 flair-0.4.0 gensim-3.4.0 matplotlib-3.0.0 mpld3-0.3 pytorch-pretrained-bert-0.3.0 segtok-1.5.7 sqlitedict-1.6.0 tqdm-4.26.0 typing-3.6.4\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [matplotlib, mpl_toolkits, tqdm, typing]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A6zI8n91w_QL",
        "colab_type": "code",
        "outputId": "40d03fa9-6ec2-4fe0-813c-403fda52ec9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "### Importing the Dataset\n",
        "import io\n",
        "data = pd.read_csv(io.StringIO(train1.GetContentString()))  ## contain test+train tweets\n",
        "print(data.head())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-01-21 11:27:51,155 file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "   Unnamed: 0  label                                              tweet\n",
            "0           0    0.0    user when a father is dysfunctional and is s...\n",
            "1           1    0.0   user  user thanks for  lyft credit i can t us...\n",
            "2           2    0.0                                bihday your majesty\n",
            "3           3    0.0   model   i love u take with u all the time in ...\n",
            "4           4    0.0             factsguide  society now     motivation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0rQcX0KgxR_c",
        "colab_type": "code",
        "outputId": "b9c3a9ca-ca4c-4643-e5e8-0d42938ebf0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "text = data['tweet'] #extracting the text part\n",
        "text.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      user when a father is dysfunctional and is s...\n",
              "1     user  user thanks for  lyft credit i can t us...\n",
              "2                                  bihday your majesty\n",
              "3     model   i love u take with u all the time in ...\n",
              "4               factsguide  society now     motivation\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "4c67gUjhxlAU",
        "colab_type": "code",
        "outputId": "66716e76-e0be-4ce3-b69d-102772308a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "k = text.tolist() ## Text to python list for iteration\n",
        "print(k[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['  user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction     run', ' user  user thanks for  lyft credit i can t use cause they don t offer wheelchair vans in pdx      disapointed  getthanked', '  bihday your majesty', ' model   i love u take with u all the time in ur                                      ', ' factsguide  society now     motivation', '      huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo  ', '  user camping tomorrow  user  user  user  user  user  user  user danny   ', 'the next school year is the year for exams      can t think about that       school  exams    hate  imagine  actorslife  revolutionschool  girl', 'we won    love the land     allin  cavs  champions  cleveland  clevelandcavaliers      ', '  user  user welcome here    i m   it s so  gr    ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fuBf62FqjBuI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "BihsaBM-x0C-",
        "colab_type": "code",
        "outputId": "fefe22d5-4a49-4d28-bd6d-1d108f9c90bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.embeddings import CharacterEmbeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "# init standard GloVe embedding\n",
        "#glove_embedding = WordEmbeddings('glove')\n",
        "# init standard character embeddings\n",
        "#character_embeddings = CharacterEmbeddings()\n",
        "#twitter = WordEmbeddings('twitter')\n",
        "flair_forward  = FlairEmbeddings('news-forward-fast')\n",
        "flair_backward = FlairEmbeddings('news-backward-fast')\n",
        "\n",
        "stack = StackedEmbeddings( embeddings = [ flair_forward, flair_backward ])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-01-21 11:27:52,443 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpgldatrmt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 47207378.74B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-01-21 11:27:53,011 copying /tmp/tmpgldatrmt to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2019-01-21 11:27:53,038 removing temp file /tmp/tmpgldatrmt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-01-21 11:27:56,003 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpwc80y5up\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 40716062.47B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-01-21 11:27:56,760 copying /tmp/tmpwc80y5up to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-01-21 11:27:56,795 removing temp file /tmp/tmpwc80y5up\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QQbGxfdmjHl1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Flair types"
      ]
    },
    {
      "metadata": {
        "id": "LXNeFgxH0HCg",
        "colab_type": "code",
        "outputId": "0da5812b-6bf2-4ecb-e9f2-7bf04e111de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "# create a sentence\n",
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# embed words in sentence\n",
        "stack.embed(sentence)\n",
        "for token in sentence:\n",
        "  print(token.embedding)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 3.0558e-03, -8.9402e-08,  3.2061e-07,  ..., -1.6456e-09,\n",
            "        -7.8441e-05,  1.6318e-02])\n",
            "tensor([ 8.3728e-03, -8.8324e-07,  6.8124e-07,  ..., -1.9470e-06,\n",
            "         6.3773e-04,  5.7139e-03])\n",
            "tensor([ 2.2655e-03, -5.2416e-06,  5.9481e-07,  ..., -9.3616e-07,\n",
            "         1.6768e-05,  2.9047e-04])\n",
            "tensor([ 7.8900e-04, -8.2879e-07,  1.1457e-06,  ..., -4.5412e-08,\n",
            "        -1.1528e-04,  3.4503e-02])\n",
            "tensor([ 1.7806e-03,  9.4982e-08,  7.0174e-08,  ..., -1.0784e-08,\n",
            "        -4.4279e-06,  2.0673e-03])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UI8feVruU1FK",
        "colab_type": "code",
        "outputId": "cdf994af-e731-4038-baf4-82c1512c7a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Size of embedding\n",
        "z = token.embedding.size()[0]\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TG6FQD4B4y3j",
        "colab_type": "code",
        "outputId": "5c64029d-3ee8-45f6-b5cf-e845569673c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Calculating Document Embeddin\n",
        "\n",
        "s = torch.zeros(0,z)    # creating a tensor for storing sentence embeddings\n",
        "\n",
        "for tweet in tqdm(k):   # iterating Sentences\n",
        "  w = torch.zeros(0,z)   # tensor for words\n",
        "  sentence = Sentence(tweet)\n",
        "  stack.embed(sentence)\n",
        "  for token in sentence:\n",
        "    w = torch.cat((w,token.embedding.view(-1,z)),0)   # storing word Embeddings in a sentence\n",
        "  s = torch.cat((s, w.mean(dim = 0).view(-1, z)),0)   # storing sentence Embeddings\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 44479/49159 [53:51<08:58,  8.69it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QFm20AKnXJGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s.size()   # size of Document Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GMb_9iZk3yK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Partitioning of data"
      ]
    },
    {
      "metadata": {
        "id": "M0hwtm8F1ERa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = s.numpy()                 # Bulk Data\n",
        "test = X[31962:,:]\n",
        "train = X[:31962,:]\n",
        "target = data['label'][data['label'].isnull()==False].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfLJ5LA8lO6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementing XGBoost"
      ]
    },
    {
      "metadata": {
        "id": "Y4-66EfvZRzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train, target,  \n",
        "                                                          random_state=42, \n",
        "                                                          test_size=0.3)\n",
        "\n",
        "\n",
        "dtrain = xgb.DMatrix(x_train,y_train)          # XGB compatible data\n",
        "dvalid = xgb.DMatrix(x_valid, label = y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YrjjbrslT50",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom Evaluator"
      ]
    },
    {
      "metadata": {
        "id": "q6kZKHLOZlje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def custom_eval(preds, dtrain):\n",
        "    labels = dtrain.get_label().astype(np.int)\n",
        "    preds = (preds >= 0.3).astype(np.int)\n",
        "    return [('f1_score', f1_score(labels, preds))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dLdow_0PlgCu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### parameters"
      ]
    },
    {
      "metadata": {
        "id": "u_ZuUqDMYdVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'colsample': 0.9,\n",
        " 'colsample_bytree': 0.5,\n",
        " 'eta': 0.1,\n",
        " 'max_depth': 8,\n",
        " 'min_child_weight': 6,\n",
        " 'objective': 'binary:logistic',\n",
        " 'subsample': 0.9\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHTCY7tYJdWB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    feval= custom_eval,\n",
        "    num_boost_round= 1000,\n",
        "    maximize=True,\n",
        "    evals=[(dvalid, \"Validation\")],\n",
        "    early_stopping_rounds=30\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFhFGPKzbfYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reformating test set fo XGB\n",
        "dtest = xgb.DMatrix(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sopuLNLKccJ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict = xgb_model.predict(dtest) # predicting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Yq_gK-5bdOX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0_KQBWpdEw_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k = range(31963,49160) ## id for submission file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-x5WDGQol__e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "predictions are in form of Probability :  \n",
        "Converting them to Labels using various threshold."
      ]
    },
    {
      "metadata": {
        "id": "nwhS2LoMLXM0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "th = [0.1,0.2,0.3,0.4]\n",
        "for i in th:\n",
        "  extract1 = []               # Stores labels generated\n",
        "  for j in predict:\n",
        "    if j<i:                    \n",
        "      extract1.append(0)\n",
        "    else:\n",
        "      extract1.append(1)\n",
        "  final = pd.DataFrame({ 'id'   : k,\n",
        "                         'label': extract1,})\n",
        "  final = final.set_index('id')\n",
        "  from google.colab import files\n",
        "  final.to_csv('stack'+str(i)+'.csv')\n",
        "  files.download('stack'+str(i)+'.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTUiZb-Nmgm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}